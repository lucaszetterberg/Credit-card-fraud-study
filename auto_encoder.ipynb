{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto Encoder\n",
    "\n",
    "This is the auto encoder implementation that is going to be used in our study, the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub # Gather data from kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "file = os.path.join(path, \"creditcard.csv\")\n",
    "df = pd.read_csv(file)\n",
    " \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      " Class\n",
      "0    0.998271\n",
      "1    0.001729\n",
      "Name: proportion, dtype: float64\n",
      "Testing set class distribution:\n",
      " Class\n",
      "0    0.99828\n",
      "1    0.00172\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Data split (organization of training and test data)\n",
    "x = df.drop(columns=['Class'])  # Extracts all features except target\n",
    "y = df['Class']  # Extracts only the target feature\n",
    "\n",
    "# Split dataset into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, \n",
    "                                                    random_state=15, \n",
    "                                                    stratify=y)\n",
    "\n",
    "# Check class distribution in training and testing sets\n",
    "print(\"Training set class distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Testing set class distribution:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto Encoder model\n",
    "input_dimension = x_train.shape[1]\n",
    "hidden_layer = 16\n",
    "input_layer = Input(shape=(input_dimension,))\n",
    "Encoder1 = Dense(hidden_layer,activation=\"tanh\")(input_layer)\n",
    "Encoder2 = Dense(int(hidden_layer/2),activation=\"tanh\")(Encoder1)\n",
    "Encoder3 = Dense(int(hidden_layer/4),activation=\"tanh\")(Encoder2)\n",
    "Decoder1 = Dense(int(hidden_layer/4),activation=\"tanh\")(Encoder3)\n",
    "Decoder2 = Dense(int(hidden_layer/2),activation=\"tanh\")(Decoder1)\n",
    "Decoder3 = Dense(input_dimension,activation=\"tanh\")(Decoder2)\n",
    "AutoEncoderModel = Model(inputs=input_layer,outputs=Decoder3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "AutoEncoderModel.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 375059072.0000 - val_loss: 375830240.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 374015232.0000 - val_loss: 375830240.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374519968.0000 - val_loss: 375830240.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374385952.0000 - val_loss: 375830240.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374856480.0000 - val_loss: 375830240.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 375204928.0000 - val_loss: 375830240.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 373920224.0000 - val_loss: 375830240.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 374764320.0000 - val_loss: 375830240.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374599360.0000 - val_loss: 375830240.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374769504.0000 - val_loss: 375830240.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374684384.0000 - val_loss: 375830240.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 374164192.0000 - val_loss: 375830240.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 375621632.0000 - val_loss: 375830240.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374087040.0000 - val_loss: 375830240.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374945184.0000 - val_loss: 375830240.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 375301664.0000 - val_loss: 375830240.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 376036288.0000 - val_loss: 375830240.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 373869248.0000 - val_loss: 375830240.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374475744.0000 - val_loss: 375830240.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 374763520.0000 - val_loss: 375830240.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374622528.0000 - val_loss: 375830240.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 373943328.0000 - val_loss: 375830240.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 375892864.0000 - val_loss: 375830240.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374378272.0000 - val_loss: 375830240.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 374659840.0000 - val_loss: 375830240.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 374170240.0000 - val_loss: 375830240.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 376260352.0000 - val_loss: 375830240.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 372937248.0000 - val_loss: 375830240.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 374267296.0000 - val_loss: 375830240.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374126592.0000 - val_loss: 375830240.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 374674752.0000 - val_loss: 375830240.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374140544.0000 - val_loss: 375830240.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 374875520.0000 - val_loss: 375830240.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 374662496.0000 - val_loss: 375830240.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 374257376.0000 - val_loss: 375830240.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 375348224.0000 - val_loss: 375830240.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 375034560.0000 - val_loss: 375830240.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374022048.0000 - val_loss: 375830240.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 375126144.0000 - val_loss: 375830240.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 376158880.0000 - val_loss: 375830240.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 375006976.0000 - val_loss: 375830240.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374173120.0000 - val_loss: 375830240.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374865376.0000 - val_loss: 375830240.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374662528.0000 - val_loss: 375830240.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 375263072.0000 - val_loss: 375830240.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374013760.0000 - val_loss: 375830240.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374999296.0000 - val_loss: 375830240.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 373844960.0000 - val_loss: 375830240.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 373948928.0000 - val_loss: 375830240.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374196128.0000 - val_loss: 375830240.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4e882dacb0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoEncoderModel.fit(x_train, x_train, epochs=50, batch_size=512, validation_data=(x_test, x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
